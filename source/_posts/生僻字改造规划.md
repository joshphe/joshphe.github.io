---
title: 生僻字改造规划
date: 2022-10-10 18:30:00
img: https://cdn.jsdelivr.net/gh/joshphe/blogImage@main/img/coding.png  #设置本地图片
summary: 金融服务生僻字处理
tags:

- 生僻字
---

# 生僻字改造规划

## 一、概述

### 1、背景介绍

在过去，生僻字群众办理各类业务时采用人工书写汉字的方式，基本可以顺利开展业务。但随着信息化技术的发展，各类业务通过信息系统办理时出现姓名在信息系统中无法输入、存储、处理或显示的情况，导致生僻字与数字化转型显得 “格格不入”。

我行在业务开展过程中多次收到客户反馈因生僻字无法录入导致业务无法正常办理；存折上显示的客户姓名与身份证上的不一致等，引起客户不满。相比于原传统线下模式，数字化时代的线下处理需要投入更多时间成本，非生僻字人需要几秒钟的事情，生僻字人群可能需要 1 至 2 天，甚至无法短时间内解决，形成了生僻字客群眼前的一道 “数字鸿沟”。

#### 1.1 中文字符集的发展

**GB2312**

GB2313 是中国国家标准简体中文字符集，由中国国家标准总局于1980年发布，支持的字符

- 6763 个常用汉字
- 682 个其它字符 

**编码方式**

- 兼容 ASCII 字符
- 新增汉字和其它字符使用**两个字节**编码

**如何在字节流中区分 ASCII 字符与 GB2312 支持的字符**

- 最高位 0 的字节是 ASCII 字符
- 最高位 1 的字节 + 后续的一个字节组成 GB 2312 支持的字符

理论中的编码范围如下，实际上总共需要表示 7445 多个字符，只使用了一部分空间。

![](https://cdn.jsdelivr.net/gh/joshphe/blogImage@main/img/picture0001.png)

------

**BIG5**

由于 GB2312 不包括繁体字符，台湾同胞们不乐意了

**BIG5：** BIG-5 码是通行于台湾、香港地区的一个繁体字编码方案。使用 2 个字节表示，表示13053 个汉字

------

**GBK**

中国也有使用繁体字的需求，于是 GBK 增加了对繁体字的支持，在 **1995 年**被提出。兼容 GB2312，还是使用 2 个字节表示，可表示 21886 个字符

GBK 亦采用双字节表示，总体编码范围为 8140-FEFE，首字节在 81-FE 之间，尾字节在 40-FE 之间，剔除 xx7F 一条线。总计 23940 个码位，共收入 21886 个汉字和图形符号，其中汉字（包括部首和构件）21003 个，图形符号 883 个。

全部编码分为三大部分：

**1. 汉字区。包括：**

a. GB 2312 汉字区。即 GBK/2: B0A1-F7FE。收录 GB 2312 汉字 6763 个，按原顺序排列。

b. GB 13000.1 扩充汉字区。包括：

(1) GBK/3: 8140-A0FE。收录 GB 13000.1 中的 CJK 汉字 6080 个。

(2) GBK/4: AA40-FEA0。收录 CJK 汉字和增补的汉字 8160 个。CJK 汉字在前，按 UCS 代码大小排列；增补的汉字（包括部首和构件）在后，按《康熙字典》的页码/字位排列。

**2. 图形符号区。包括：**

a. GB 2312 非汉字符号区。即 GBK/1: A1A1-A9FE。其中除 GB 2312 的符号外，还有 10 个小写罗马数字和 GB 12345 增补的符号。计符号 717 个。

b. GB 13000.1 扩充非汉字区。即 GBK/5: A840-A9A0。BIG-5 非汉字符号、结构符和 “○” 排列在此区。计符号 166 个。

**3. 用户自定义区：分为(1)(2)(3)三个小区。**

(1) AAA1-AFFE，码位 564 个。

(2) F8A1-FEFE，码位 658 个。

(3) A140-A7A0，码位 672 个。

第 (3) 区尽管对用户开放，但限制使用，因为不排除未来在此区域增补新字符的可能性。

![](https://cdn.jsdelivr.net/gh/joshphe/blogImage@main/img/picture0002.png)

------

**GB18030**

随着计算机逐渐深入人民生活，发现有相当部分的人的名字包括生僻字，无法在计算机中表示。

GB18030 在 2005 年有中国国家标准化管理委员会提出。

- 支持中国国内少数民族的文字
- 汉字收录范围包含繁体汉字以及日韩汉字

**编码方式**

- 1, 2, 4 个字节的变长编码
- 一个字节兼容 ASCII 编码
- 两个字节兼容 GBK 编码
- 四个字节支持新增的字符

![](https://cdn.jsdelivr.net/gh/joshphe/blogImage@main/img/picture0003.png)

#### 1.2 生僻字问题

- **输入/显示不支持：**渠道类系统无法正常的输入和显示生僻字。
- **通讯传输乱码：**应用系统间通讯传输过程中，部分系统无法满足大字符集要求，导致转换乱码。
- **数据存储不支持：**应用系统使用的数据库字符集编码无法满足生僻字存储要求。
- **硬件设备不支持：**涉及打印、显示、识别等硬件设备内置字库无法满足生僻字要求。
- **一字多码：**因各地区编码合并，少量汉字存在一字多码的问题。

### 2、规划范围

#### 2.1 应用范围

#### 2.2 功能范围

### 3、术语定义

| **术语** | 简称/说明                                                    |
| -------- | :----------------------------------------------------------- |
| Unicode  | 统一码（ Unicode ），也叫万国码、单一码，是计算机科学领域里的一项业界标准，包括字符集、编码方案等。Unicode 是为了解决传统的字符编码方案的局限而产生的，它为每种语言中的每个字符设定了统一且唯一的二进制编码，以满足跨语言、跨平台进行文本转换、处理的要求。 |
| Emoji    | Emoji 是一种特殊的 Unicode 编码，常见于 IOS 和 Android 手机上。 |

## 二、生僻字涉及领域

### 1、操作系统

当我们在键盘上输入一个字符之后，计算机会通过 Unicode ，将这个字符转换成二进制。

接下来，通过获得到的 Unicode 编码值，查询字体文件中的 Charmap ，把编码值转换成字形索引，一旦获得了字形索引你便可以装载对应的字形图像。之后，就可以对这个字形图像进行图形渲染，然后就可以显示在显示器上面了，因此需要将操作系统的 Unicode 满足升级到满足生僻字要求的版本，即 Unicode 13.0 版本以上。

**一个字符想要在电脑上显示出来，需要以下三个条件：**

1、输入法支持输入这个字符

2、Unicode 编码支持将这个字符转成二进制

3、计算机上安装的字体中包含这个字符

### 2、字体

如果 Unicode 中已经包含了某个生僻字，那么在展示的时候，就会通过得到的 Unicode 编码值，查询字体文件中的 Charmap，把编码值转换成字形索引。

但是，如果预装字体中不包含某些字符的话，也是无法展示的。

也就是说，如果输入法可以兼容最新版的 Unicode 13.0，并且操作系统也升级到了最新版的 Unicode 编码，也不意味着直接就可以显示像 " biáng " 这样被最新收录的生僻字。

因为这还依赖于操作系统中的字体是否包含这个字符。目前市面上有些商业字体是可以支持 CJK 中的很多扩展字符的。

![](https://cdn.jsdelivr.net/gh/joshphe/blogImage@main/img/1665297723632.png)

### 3、输入法

目前市面上比较常见的中文输入法，大多数都是采用的 GBK 作为字符集的，GBK 共收录 21886 个汉字和图形符号，其中汉字（包括部首和构件）21003 个，图形符号 883 个。但是中文汉字远不止 2 万多，所以，很多生僻字是无法通过输入法打出来的，如 " Biángbiáng 面" 中的 biáng 字。

### 4、软件编码

Java开发过程中编解码的常见使用场景：

#### 4.1 流读取文件

具有转换编码功能的有：OutputStreamWriter和InputStreamReader

```java
// 创建指定字符集的 InputStreamReader
InputStreamReader(InputStream in, String CharsetName)
// 创建使用指定字符集的 OutputStreamWriter
OutputStreamWriter(OutputStream out, String CharsetName)
```

```java
FileInputStream inputStream = new FileInputStream(file);          
InputStreamReader reader = new InputStreamReader(inputStream, charset);
StringBuffer buffer = new StringBuffer();          
char[] buf = new char[64];          
int count = 0;          
try {
  while ((count = reader.read(buf)) != -1) {                 
   buffer.append(buf, 0, count);             
  }          
} finally {            
   reader.close();          
  }         
System.out.println(buffer);
```

每次调用 InputStreamReader 中的一个 read() 方法都会导致从底层输入流读取一个或多个字节。要启用从字节到字符的有效转换，可以提前从底层流读取更多的字节，使其超过满足当前读取操作所需的字节。API 解释非常清楚，InputStreamReader 在底层读取文件时仍然采用字节读取，读取字节后它需要根据一个指定的编码格式来解析为字符，如果没有指定编码格式则采用系统默认编码格式。

#### 4.2 处理字符串编码

```java
File file = new File("C:/Users/Aurora/Desktop/test3.txt");
InputStream is = new FileInputStream(file);
StringBuffer sb = new StringBuffer();
byte[] bytes = new byte[1024];
for(int n; (n = is.read(bytes))!=-1;){
    sb.append(new String(bytes,0,n,"UTF-8"));
}
System.out.println(sb);
```

通过字节流转化为String的过程中如果我们不指定编码为UTF-8时，则默认使用系统编码格式（GBK）来解码操作，由于两者编码格式不一致，在构造 String 的过程中会产生乱码，文件内容为 "你好世界 Hello World" ，输出为 "浣犲ソ涓栫晫 Hello World" 。

#### 4.3 处理请求参数传递编码

```java
//对字符串进行编码
java中编码：URLEncoder.encode(strUri, “UTF-8”);
//对字符串进行解码
java中解码：URLDecoder.decode(strUri, “UTF-8”);
```

#### 4.4 内存

#### 4.5 JAVAWEB编码

通过下图我们可以了解到JAVAWEB中有哪些地方有转码：

![](https://cdn.jsdelivr.net/gh/joshphe/blogImage@main/img/JAVAWEB.png)

用户想服务器发送一个 HTTP 请求，需要编码的地方有 url、cookie、parameter，经过编码后服务器接受 HTTP 请求，解析 HTTP 请求，然后对 url、cookie、parameter 进行解码。在服务器进行业务逻辑处理过程中可能需要读取数据库、本地文件或者网络中的其他文件等等，这些过程都需要进行编码解码。当处理完成后，服务器将数据进行编码后发送给客户端，浏览器经过解码后显示给用户。在这个整个过程中涉及的编码解码的地方较多，其中最容易出现乱码的位置就在于服务器与客户端进行交互的过程。

##### 4.5.1 URL方式直接访问

首先看URL的组成部分：

![](https://cdn.jsdelivr.net/gh/joshphe/blogImage@main/img/picture0004.png)

在URL中，浏览器将会对path和parameter进行编码操作。为了更好地解释编码过程，使用如下URL

```http
http://127.0.0.1:8080/perbank/我是cm?name=我是cm
```

将以上地址输入进Chrome浏览器和IE浏览器中

![](https://www.likecs.com/default/index/img?u=aHR0cHM6Ly9waWFuc2hlbi5jb20vaW1hZ2VzLzQwOC9hYzVmN2ZmYzZkYjQ2NTg5OGViZTI3MWY1YTcxYjNkOC5wbmc=)

![](https://www.likecs.com/default/index/img?u=aHR0cHM6Ly9waWFuc2hlbi5jb20vaW1hZ2VzLzgzMi83MGQ5Y2Y0ZTUzODkyNjkxMzhhN2NhZDBiZmMxNWY4MC5wbmc=)

可以看到各大浏览器对 “我是” 的编码情况如下：

|        | path部分          | Query String      |
| ------ | ----------------- | ----------------- |
| Chrome | E6 88 91 E6 98 AF | E6 88 91 E6 98 AF |
| IE     | E6 88 91 E6 98 AF | CE D2 CA C7       |

对于path部分，chrome和IE都是采用utf-8编码格式，对于Query String部分，chrome采用的是utf-8编码，IE采用GBK。

当然对于不同的浏览器，相同浏览器不同版本，不同的操作系统等环境都会导致编码结果不同，上表某一种情况，对于URL编码规则下任何结论都是过早的。

解析请求的 URL 是在 org.apache.coyote.HTTP11.InternalInputBuffer 的 parseRequestLine 方法中，这个方法把传过来的 URL 的 byte[] 设置到 org.apache.coyote.Request 的相应的属性中。这里的 URL 仍然是 byte 格式，转成 char 是在 org.apache.catalina.connector.CoyoteAdapter 的 convertURI 方法中完成的：

对 URL 的解码操作是首先获取 Connector 的解码集，该配置在 server.xml 中

```java
<Connector URIEncoding="utf-8"/>
```

如果没有定义则会采用默认编码ISO-8859-1来解析。

从上面代码可以看出对 query String 的解码格式要么采用设置的编码，要么采用默认的解码格式 ISO-8859-1

URIEncoding 是对所有 GET 方式的请求的数据进行统一的重新编码（解码），而 useBodyEncodingForURI 是根据 post 请求的编码决定URI的编码

上面部分详细介绍了 URL 方式请求的编码解码过程。其实对于我们而言，我们更多的方式是通过表单的形式来提交。

##### 4.5.2 表单GET和POST

**表单GET**

当用户点击 submit 提交表单时，浏览器会根据设定的编码来编码数据传递给服务器。通过GET方式提交的数据都是拼接在 URL 后面（可以当做 query String ）来提交的，所以tomcat服务器在进行解码过程中URIEncoding就起到作用了。tomcat服务器会根据设置的URIEncoding来进行解码，如果没有设置则会使用默认的ISO-8859-1来解码。假如我们在页面将编码设置为UTF-8，而URIEncoding设置的不是或者没有设置，那么服务器进行解码时就会产生乱码。这个时候我们一般可以通过new String(request.getParameter("name").getBytes("iso-8859-1"),"utf-8") 的形式来获取正确数据。

**表单POST**

对于POST方式，它采用的编码也是由页面来决定的即contentType。当我通过点击页面的submit按钮来提交表单时，浏览器首先会根据contentType的charset编码格式来对POST表单的参数进行编码然后提交给服务器，在服务器端同样也是用contentType中设置的字符集来进行解码（这里与get方式就不同了），这就是通过POST表单提交的参数一般而言都不会出现乱码问题。当然这个字符集编码我们是可以自己设定的：request.setCharacterEncoding(charset) 。

#### 4.6 JSP页面编码

我们知道JSP页面是需要转换为servlet的，在转换过程中肯定是要进行编码的。在JSP转换为servlet过程中下面一段代码起到至关重要的作用。

```javascript
<%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="GBK" %>
```

在上面代码中有两个地方存在编码：pageEncoding、contentType的charset。其中**pageEncoding是jsp文件本身的编码，而contentType的charset是指服务器发送给客户端时的内容编码。**

在前面一篇博客中就提到过jsp在转换为Servlet的过程中是需要经过主要的三次编码转换过程（除去[数据库](http://lib.csdn.net/base/mysql)编码转换、页面参数输入编码转换）：

第一次：转换为.java文件；

第二次：转换为.class文件；

第三次：业务逻辑处理后输出。

**第一阶段**

JVM将JSP编译为.jsp文件。在这个过程中pageEncoding就起到作用了，JVM首先会获取pageEncoding的值，如果该值存在则采用它设定的编码来编译，否则则采用file.encoding编码来编译。

**第二阶段**

JVM将.java文件转换为.class文件。在这个过程就与任何编码的设置都没有关系了，不管JSP采用了什么样的编码格式都将无效。经过这个阶段后.jsp文件就转换成了统一的Unicode格式的.class文件了。

**第三阶段**

后台经过业务逻辑处理后将产生的结果输出到客户端。在这个过程中contentType的charset就发挥了功效。如果设置了charset则浏览器就会使用指定的编码格式进行解码，否则采用默认的ISO-8859-1编码格式进行解码处理。

流程如如下：

![](https://www.likecs.com/default/index/img?u=aHR0cHM6Ly9waWFuc2hlbi5jb20vaW1hZ2VzLzk1My9mOGZjZjQxMjNmMjFmNTA4MzI3ZjcwZGNkMjZjYWIwOS5KUEVH)

> 转载自[java中文解码_java中文乱码解决之道（六）-----javaWeb中的编码解码_hey one的博客-CSDN博客](https://blog.csdn.net/weixin_29021291/article/details/114234494)

### 5、数据库编码

数据库在使用默认编码如 Oracle 使用 **ZHS16GBK**，Mysql使用 **UTF-8** 编码时，在保存生僻字或 emoji 字符时会异常乱码，无法正常保存。

以 Mysql 为例，由官方文档可知，Mysql 支持的 utf8 编码最大字符长度为 3 字节，如果遇到 4 字节的宽字符就会插入异常了。三个字节的 UTF-8 最大能编码的 Unicode 字符时 0xffff，也就是 Unicode 中的基本多文种平面 （BMP） 。任何不在基本多文本平面的 Unicode字符，都无法使用 Mysql 的 utf8 字符集存储，包括 emoji 表情和很多不常用的汉字，以及任何新增的 Unicode 字符等。

要在 Mysql 中保存 4 字节长度的 UTF-8 字符，需要使用 utf8mb4 字符集，该字符集只有 5.5.3 版本以后才支持。

#### 5.1 MYSQL

MYSQL数据库建议使用 uft8mb4 字符集满足生僻字的存储。

![Mysql字符集设置](https://cdn.jsdelivr.net/gh/joshphe/blogImage@main/img/mysql-setting.png)

#### 5.2 Oracle

